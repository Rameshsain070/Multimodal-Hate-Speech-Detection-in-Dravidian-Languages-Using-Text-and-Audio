Project Title: Multimodal Hate Speech Detection in Low-Resource Dravidian Languages1. Executive SummaryThis research project focuses on the automated detection of hate speech in Dravidian languages (Malayalam, Tamil, and Telugu), which are often under-represented in major AI safety research. Addressing the complexity of social media content, the system utilizes a Multimodal Late Fusion Architecture, combining acoustic features from audio recordings with semantic features from text transcripts. By ensembling state-of-the-art Transformer models for text and Speech Foundation Models (SFMs) for audio, the system achieves robust classification performance even in the presence of code-mixed language (e.g., Tanglish) and noisy audio environments.2. Problem StatementHate speech detection in Indian regional languages faces unique challenges:Code-Mixing: Social media users often mix English with native scripts (e.g., writing Tamil words in English characters), confusing traditional NLP models.Tonal Context: Text transcripts often miss the sarcasm, aggression, or emotion present in the speaker's voice, which are critical for distinguishing between "offensive" and "hate" speech.Data Scarcity: Unlike English, high-quality labeled datasets for Dravidian languages are limited ("low-resource").3. System Architecture & MethodologyThis project implements a Stacking Ensemble (Meta-Learning) approach. Instead of a single model, it trains multiple "expert" models independently and fuses their outputs using a final classifier.Phase 1: The Text Stream (Natural Language Processing)The system processes the text transcripts using three distinct Transformer-based Large Language Models (LLMs) to capture different linguistic nuances:mBERT (Multilingual BERT): Provides a strong baseline understanding of 104 languages.XLM-RoBERTa (XLM-R): Optimized for cross-lingual understanding, handling code-mixed data effectively.IndicBERT v2: A model pre-trained specifically on Indian languages, offering superior grasp of Dravidian syntax and vocabulary.Phase 2: The Audio Stream (Speech Signal Processing)Raw audio waveforms are processed to extract paralinguistic features (tone, pitch, emotion). To ensure robustness against real-world noise, Data Augmentation (Gaussian Noise, Time Stretch, Pitch Shift) is applied using audiomentations.Wav2Vec2 (XLSR-53): A massive multilingual speech model fine-tuned for language-specific nuances (using Tamil/Telugu specific checkpoints).WavLM: Specifically designed to capture non-semantic speech details like speaker identity and background noise, aiding in context detection.MMS (Massively Multilingual Speech): Meta’s latest speech model, offering high-performance support for over 1,000 languages, including Dravidian dialects.Phase 3: Late Fusion (The Meta-Learner)The probability scores (logits) from all 6 models (3 Text + 3 Audio) are extracted and concatenated into a feature vector. A LightGBM (Gradient Boosting Machine) classifier acts as the meta-learner. It learns to weigh the confidence of each model dynamically—for instance, prioritizing audio models when the text is ambiguous, or text models when the audio is too noisy.4. Technologies & Tools UsedDomainTools / LibrariesDeep Learning FrameworkPyTorch, Hugging Face Transformers, AccelerateAudio ProcessingLibrosa, SoundFile, AudiomentationsMachine LearningScikit-learn, LightGBM (for fusion)Data HandlingPandas, NumPy, Datasets (Hugging Face)VisualizationMatplotlib (for Confusion Matrices & ROC Curves)5. Key Innovations & ImpactLanguage-Specific Fine-Tuning: Unlike generic approaches, this project fine-tunes separate pipelines for Malayalam, Tamil, and Telugu, preserving the unique phonetics and grammar of each language.Robustness via Augmentation: The inclusion of audio augmentations ensures the model isn't just memorizing clean studio recordings but can handle the noisy, lower-quality audio typical of social media.Superior Accuracy: By fusing modalities, the system overcomes the limitations of unimodal (text-only or audio-only) classifiers, significantly reducing false positives in hate speech detection.
